{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96086dd-3db9-428a-aa82-4fb36dda5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lm-format-enforcer -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd5520d7-0d78-4533-a8f9-96beb689b8a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T01:33:19.980628Z",
     "iopub.status.busy": "2024-09-08T01:33:19.980203Z",
     "iopub.status.idle": "2024-09-08T01:33:19.996296Z",
     "shell.execute_reply": "2024-09-08T01:33:19.995467Z",
     "shell.execute_reply.started": "2024-09-08T01:33:19.980600Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4560d742-3296-4e63-a580-c46b7292a2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T00:57:57.699644Z",
     "iopub.status.busy": "2024-09-08T00:57:57.699323Z",
     "iopub.status.idle": "2024-09-08T01:26:26.648959Z",
     "shell.execute_reply": "2024-09-08T01:26:26.648267Z",
     "shell.execute_reply.started": "2024-09-08T00:57:57.699619Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 09-08 00:57:58 config.py:1651] Casting torch.float16 to torch.bfloat16.\n",
      "INFO 09-08 00:57:58 llm_engine.py:213] Initializing an LLM engine (v0.6.0) with config: model='./llm', speculative_config=None, tokenizer='./llm', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=./llm, use_v2_block_manager=False, num_scheduler_steps=1, enable_prefix_caching=False, use_async_output_proc=True)\n",
      "INFO 09-08 01:01:11 model_runner.py:915] Starting to load model ./llm...\n",
      "WARNING 09-08 01:01:13 interfaces.py:132] The model (<class 'vllm.model_executor.models.commandr.CohereForCausalLM'>) contains all LoRA-specific attributes, but does not set `supports_lora=True`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/14 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:   7% Completed | 1/14 [01:44<22:32, 104.05s/it]\n",
      "Loading safetensors checkpoint shards:  14% Completed | 2/14 [03:30<21:04, 105.40s/it]\n",
      "Loading safetensors checkpoint shards:  21% Completed | 3/14 [03:47<11:57, 65.26s/it]\n",
      "Loading safetensors checkpoint shards:  29% Completed | 4/14 [05:33<13:32, 81.24s/it]\n",
      "Loading safetensors checkpoint shards:  36% Completed | 5/14 [07:20<13:33, 90.41s/it]\n",
      "Loading safetensors checkpoint shards:  43% Completed | 6/14 [09:06<12:47, 95.94s/it]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 7/14 [10:51<11:31, 98.76s/it]\n",
      "Loading safetensors checkpoint shards:  57% Completed | 8/14 [12:38<10:07, 101.32s/it]\n",
      "Loading safetensors checkpoint shards:  64% Completed | 9/14 [14:29<08:41, 104.33s/it]\n",
      "Loading safetensors checkpoint shards:  71% Completed | 10/14 [16:15<06:59, 105.00s/it]\n",
      "Loading safetensors checkpoint shards:  79% Completed | 11/14 [18:00<05:14, 104.80s/it]\n",
      "Loading safetensors checkpoint shards:  86% Completed | 12/14 [19:46<03:30, 105.38s/it]\n",
      "Loading safetensors checkpoint shards:  93% Completed | 13/14 [21:33<01:45, 105.81s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 14/14 [23:20<00:00, 106.11s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 14/14 [23:20<00:00, 100.03s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-08 01:24:34 model_runner.py:926] Loading model weights took 60.1881 GB\n",
      "INFO 09-08 01:25:58 gpu_executor.py:122] # GPU blocks: 3159, # CPU blocks: 1638\n",
      "INFO 09-08 01:25:59 model_runner.py:1217] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-08 01:25:59 model_runner.py:1221] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-08 01:26:26 model_runner.py:1335] Graph capturing finished in 27 secs.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./llm')\n",
    "llm = LLM(\n",
    "    model='./llm',\n",
    "    dtype=torch.bfloat16,\n",
    "    gpu_memory_utilization=0.9,\n",
    "    max_seq_len_to_capture=8192,\n",
    "    max_model_len=8192,\n",
    "    # enforce_eager=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2182420d-d6e8-4744-8c85-b36366926bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:19:24.767369Z",
     "iopub.status.busy": "2024-09-08T03:19:24.766967Z",
     "iopub.status.idle": "2024-09-08T03:19:37.111763Z",
     "shell.execute_reply": "2024-09-08T03:19:37.110989Z",
     "shell.execute_reply.started": "2024-09-08T03:19:24.767350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lmformatenforcer import CharacterLevelParser\n",
    "from lmformatenforcer.integrations.vllm import (\n",
    "    build_vllm_logits_processor,\n",
    "    build_vllm_token_enforcer_tokenizer_data\n",
    ")\n",
    "from typing import Union, List, Optional, Dict\n",
    "from vllm import SamplingParams\n",
    "\n",
    "ListOrStrList = Union[str, List[str]]\n",
    "\n",
    "tokenizer_data = build_vllm_token_enforcer_tokenizer_data(llm)\n",
    "\n",
    "genetation_kwargs = {\n",
    "    'temperature': 0.2,\n",
    "    'top_p': 0.7,\n",
    "    # 'top_k': 30,\n",
    "    'max_tokens': 1024,\n",
    "    'repetition_penalty': 1.12\n",
    "}\n",
    "def vllm_with_character_level_parser(\n",
    "    user_prompt: ListOrStrList,\n",
    "    genetation_kwargs: Optional[Dict[str, Union[int, float]]] = None,\n",
    "    parser: Optional[CharacterLevelParser] = None\n",
    ") -> ListOrStrList:\n",
    "    \n",
    "    sampling_params = SamplingParams() if genetation_kwargs is None else SamplingParams(**genetation_kwargs)\n",
    "\n",
    "    if parser:\n",
    "        logits_processor = build_vllm_logits_processor(tokenizer_data, parser)\n",
    "        sampling_params.logits_processors = [logits_processor]\n",
    "    # results = llm.generate(prompt, sampling_params=sampling_params)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    \n",
    "    prompt = llm.llm_engine.tokenizer.tokenizer.apply_chat_template(\n",
    "        conversation=messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False\n",
    "    )\n",
    "    prompts = [prompt]\n",
    "    \n",
    "    results = llm.generate(prompts, sampling_params)\n",
    "    \n",
    "    if isinstance(user_prompt, str):\n",
    "        return results[0].outputs[0].text\n",
    "    else:\n",
    "        return [result.outputs[0].text for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8954113d-6b28-44d7-ae5f-348fe8981778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:19:37.113457Z",
     "iopub.status.busy": "2024-09-08T03:19:37.112944Z",
     "iopub.status.idle": "2024-09-08T03:19:37.125423Z",
     "shell.execute_reply": "2024-09-08T03:19:37.124854Z",
     "shell.execute_reply.started": "2024-09-08T03:19:37.113437Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lmformatenforcer import JsonSchemaParser\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Tuple\n",
    "import datetime\n",
    "\n",
    "\"\"\"\n",
    "Структура JSON файла, как будут генерироваться ответы LLM\n",
    "Сделано для упрощения пост процессинга данных\n",
    "\"\"\"\n",
    "class AnswerFormat(BaseModel):\n",
    "    conference_name: str # название совещания\n",
    "    conference_date: datetime.date # дата проведения совещания\n",
    "    users_name: List[str] # имена участников конференции\n",
    "    user_status: List[str] # должности участников конференции\n",
    "    question_title: List[str] # название вопроса\n",
    "    questions: List[str] # вопросы, обсуждаемые на совещании\n",
    "    solutions: List[str] # решения по каждому отдельному вопросу\n",
    "    responsible_person: List[str] # список лиц, ответственных за задания\n",
    "    time_for_solutions: List[datetime.date] # крайний срок решения задачи\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b85c9462-e17d-4e20-acf7-9e9a5a813fcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:26:45.026720Z",
     "iopub.status.busy": "2024-09-08T03:26:45.025948Z",
     "iopub.status.idle": "2024-09-08T03:26:45.087544Z",
     "shell.execute_reply": "2024-09-08T03:26:45.086925Z",
     "shell.execute_reply.started": "2024-09-08T03:26:45.026695Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "USER_PROMPT = \"\"\"\n",
    "Ты занимаешься поиском важной информации из расшифровок совещаний. Тебе необходимо найти во входном тексте следующую информацию:\n",
    "1. Название совещания\n",
    "2. Дата совещания\n",
    "3. ФИО всех участников совещания\n",
    "4. Должности всех участников совещания\n",
    "5. Краткое наименование рассмотренных задач\n",
    "6. Какие задачи были рассмотрены на совещании\n",
    "7. Какое решение предполагается по каждому вопросу\n",
    "8. Список лиц, ответственных за выполнение задачи\n",
    "9. Крайний срок решения задачи\n",
    "\n",
    "При поиске информации соблюдай следующие правила:\n",
    "1. Информации может не быть в тексте. Если такое случилось, НЕ ПРИДУМЫВАЙ ТЕКСТ ОТ СЕБЯ, а напиши, что информации в тексте не найдено\n",
    "2. Ответ в тексте может быть представлен в неполном виде (например, вместо ФИО участника совещания указано только его имя, а должность может быть не указана). В таком случае напиши ту информацию, что известна достоверно\n",
    "3. В случае, если у человека не указана его должность, в ответ напиши \"Должность_неизвестна\"\n",
    "4. При ответе на пункт 2 (название совещания) напиши краткий смысл того, для чего данное совещание устраивалось. При ответе на данный вопрос используй не более 5 слов\n",
    "Например: Рассмотрение апелляции, Кадровая политика, Стратегическая сессия, Итоги судебного заседания \n",
    "5. При ответе на пункт 5 (Краткое наименование рассмотренных задач) опиши кратко смысл каждоый из рассмотренных задач\n",
    "6. При ответе на пункт 6 (Какие задачи были рассмотрены на совещании) опиши ПОДРОБНО, какие задачи были приняты к рассмотрению\n",
    "7. Ответы на пункты 7, 8 и 9 (Какое решение предполагается по каждому вопросу, Список лиц, ответственных за выполнение задачи, Крайний срок решения задачи) могут не присутствовать в тексте. Если ответов на данные вопросы нет, напиши \"неизвестно\" в каждое поле\n",
    "8. Количество строк в пунктах 6, 7, 8 и 9 должно совпадать\n",
    "9. При ответе на пункты 3, 4 (ФИО всех участников совещания, Должности всех участников совещания) НЕ ДОБАВЛЯЙ людей, которые НЕ УЧАСТВУЮТ в совещании напрямую.\n",
    "10. Ты ДОЛЖЕН вывести информацию в следующей json схеме: {json_schema}\n",
    "\n",
    "Ниже тебе даны примеры, какой текст поступает на вход и какой ответ должен быть правильным:\n",
    "=================================\n",
    "Пример текста: Апелляционный суд посредством видеоконференцсвязи рассматривает апелляционную жалобу главы Крестьянскофермерское хозяйство Дубилина александра Геннадьевича, поданную на решение Арбитражного суда Волгоградской области 12 декабря 2012го года по делу а1220042602012 по иску главы КФХ Дубилина александра геннадьевича к администрации муниципального района Волгоградской области с участием третьего лица – Стародымого сергея ивановича о взыскании денежных средств в виде убытков. Пожалуйста, уважаемые коллеги представьтесь, кто осуществляет помощью в проведении и видеоконференцсвязь со стороны Арбитражного суда Волгоградской области. Судебное поручение исполняет судья Сотникова. Протокол судебного заседания ведет помощник судьи – Наумкина. У нас явилась представитель истца. Ответчик и третье лицо извещены надлежащим образом. Явка представителям не обеспечили. Стороны у нас извещены надлежащим образом.\n",
    "Правильный вывод:\n",
    "1. Название совещания: рассмотрение апелляционной жалобы\n",
    "2. Дата совещания: неизвестна\n",
    "3. ФИО всех участников совещания: Дубилин Александр Геннадиевич, Стародымов Сергей Иванович,  Сотникова, Наумкина\n",
    "4. Должности всех участников совещания: заявитель, обвиняемый, судья, помощник судьи\n",
    "5. Краткое наименование рассмотренных задач: апелляционная жалоба\n",
    "6. Какие задачи были рассмотрены на совещании: была рассмотрена жалоба о взыскании денежных средств в виде убытков\n",
    "7. Какое решение предполагается по каждому вопросу: неизвестно\n",
    "8. Список лиц, ответственных за выполнение задачи: неизвестно\n",
    "9. Крайний срок решения задачи: неизвестно\n",
    "\n",
    "\n",
    "Текст для поиска информации:\n",
    "Давайте задокументируем дату собрания - 27 сентября 2023 года. Да, здравствуйте. Яна, Аня и Егор. Сегодня мы на троих проводим совещание. Расскажите, пожалуйста, про ваше ощущение от дня, от предыдущего совещания, которое мы записали. Сделаем выводы, поставим уроки. Ну и что вам завтра хорошенького хотелось бы сделать для нашей организации. Ну и для нашей команды. Сегодня вы познакомились со многими. Расскажите ваши ощущения. Аня, начните. По алфавиту вы первая. Так несправедливо. Справедливо. Ну, за сегодняшний день мы закончили практически кейс на фотон. Но осталась довольно, конечно, большая часть. Но я думаю, мы управимся до завтрашнего дня и сделаем большое дело для Омской области. На завтра, наверное, как раз таки хотелось его закончить и закончить речь. Я на вас... На завтра вы не завершите речи. Хакатон — это очень обширная история. Там надо посидеть, там ещё денёк обменить, чтобы она сложилась. Ну и вообще, конечно, это будет качественное решение. То есть если мы реально предложим датасет, который состоит из трёх частей аудиозаписи, потом расшифровка и протокол встречи, будет вообще толстый. Будет прям пускобомба. Нам действительно нужно 15 лет, мне кажется, это вообще на несколько дней. Ну, надо вот такие маленькие, типа 10 минут записывать какие-то, или сразу расшифровку брать и расшифровку эту потом спокойно прогонять через... Прям плохая расшифровка. Да, хорошо видно. То есть надо что-то править. То есть там пунктуации, конечно, нет, но надо что-то делать. Вот так. Так что это, ну, большая задача, которую надо закрыть в ближайшие дни. И потом сделать презу на речи. Я думаю, это две крупнейшие задачи на неделе. Презентацию сделать? Ну, по речи. Я скинул шаблон? Что? Ну, през это сокращение. Не поймешь. Да, презентация. През и презентация. Ну, мы записываем уже, а дальше разб погодные условия, шторм, ураган, сегодня был хороший день, мы много работали, познакомились с очень важными и интересными людьми, набрались опыта от общения, от коммуникации, от возможностей Зарядились мотивацией Много работали Какой у вас опыт от людей? Мы узнали о том Какие есть перспективы развития Какие? Мы начали бояться своего начальника Почему? Меньше выпендриваться и вы не начали. То есть вот так вот, мое самовыражение... Задача — наладить больше коннекта. Существует все-таки такое ограничение сотрудников, как бы не чувствуется возможность какого-то там личностного... Чего? Выпендрежа. Выпендрежа? Не хватает пространства для выпендрежа? Неправда, простите меня, я не права, я так больше никогда не буду, мне очень стыдно. До сих пор выпендриваете, вы понимаете, насколько у вас много пространства? Я так больше никогда не буду. Окей, не делайте. Ну и? В общем, сегодня мы работали над очень интересной задачей Мы продолжали разработку нашего кейса на Хакатон Это очень такая тяжелая работа, потому что приходилось анализировать большой поток информации Сложно осуществлять поиск, потому что информация все-таки Вы-то знаете, это глобальная с сеть, которой очень много разной информации, очень тяжело её фильтровать, чтобы она была полезна. Мы с этой сложной задачей почти справились. Далее мы занимались работой с новыми информационными цифровыми технологиями, узнали новый сайт, который прорабатывает видео в текст. Это было полезно. Далее мы занимались наиважнейшей работой мы слушали текст и сопоставляли его с чем но стран скреби раваны информацией вот потрясающий сегодняшний сегодня день считаю что он очень полезен был на завтра еще много задач конечно не. Не стоит забывать про то, что в первой половине дня мы выполнили очень важную срочную задачу. Мы составили экселевскую таблицу по перспективам в ФАИВах в сфере искус Это очень крутая тема. Я вам обратную связь, можно там уже? Мы обсудили после обеда, видели видео с Александром и Фёдором. Созванивались, чётко приняли, сказали, всё очень круто, и прямо по твоей таблице сверху до низу начали уже прям писать всем руководителям, типа, давайте с вами свяжемся, проработаем точно тонкости, как внедрить искусственный интеллект у вас, обратную связь, чтобы составить потом список и передать куда необходимо на ту сторону речки. Вот. А вторая часть, мы по опроснику, на него будет опираться руководитель при ведении беседы. Вот так. То есть у нас будет по факту отличный кейс для правительства, который мы сможем дальше прорабатывать. Благодаря вашему труду. Спасибо вам большое. Аня и Яна. Это было немногоства, который мы сможем дальше прорабатывать. Благодаря вашему труду, спасибо вам большое. Аня и Яна, это было немного времени, но мы классно организовали труд утром, правда, и там выделили сразу у Яны сильная сторона, это генерация информации, у тебя порядок, и порядок и технический склад ума, который, ну, это все как с формул все сделает, поэтому я подумал заранее, что будет правильно именно так разделить работу, и мы эффективнее справимся. А, мы с вами такая комбо. Да. А потом, можно я вам тонкость расскажу? Мне так, ну ладно, потом в конце практики расскажу эту всю новость. Не под записи. Окей. Не под записи. Да. Может, мы хотели переслушивать это? Я вечером буду слушать. Ну да, вот потом отдадут же разработчикам. Ну, короче, это очень крутая тема. Мы проработали важный момент, который реально полезен для Родины. Это первый план. Служим России. Служим России. Да. Коллеги, завтра у нас очень важный день. Что завтра делать будем? Нам предстоит закончить работу над Хакатон. Ну, продолжить работу над Хакатон. Да, закончить Хакатон, проанализировать еще очень много информации, подготовить набор информации, датасет. Мне кажется, мы завтра весь день этому посвятим. Надо нормально как-то нарезать. А, завтра еще встреча. За полдня на это это всё идёт, две встречи у меня. Завтра. Надо нарезать всю эту историю. — Ну, я сегодня вечером ещё допишу. — Да, сегодня... Да, я нашёл ссылку на совещание правительства по 15 минут. Там, типа, тоже есть высказывания, несколько руководителей. — Сейчас Лукашенко закончим. — Да, Лукашенко делайте, и потом Мишустин, там, остальные. — Да, Лукаш остальные, они выступают.\n",
    "\"\"\".format(json_schema=AnswerFormat.schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea1bc0cb-cb22-4b68-8eb9-70f7ee3a323f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:26:45.774579Z",
     "iopub.status.busy": "2024-09-08T03:26:45.774153Z",
     "iopub.status.idle": "2024-09-08T03:27:18.341756Z",
     "shell.execute_reply": "2024-09-08T03:27:18.341196Z",
     "shell.execute_reply.started": "2024-09-08T03:26:45.774553Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████| 1/1 [00:32<00:00, 32.54s/it, est. speed input: 100.09 toks/s, output: 17.55 toks/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "result = vllm_with_character_level_parser(USER_PROMPT, genetation_kwargs, JsonSchemaParser(AnswerFormat.schema()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bc9873a6-5f5f-4a83-be43-2f255acffd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:27:18.343272Z",
     "iopub.status.busy": "2024-09-08T03:27:18.342760Z",
     "iopub.status.idle": "2024-09-08T03:27:18.356633Z",
     "shell.execute_reply": "2024-09-08T03:27:18.356087Z",
     "shell.execute_reply.started": "2024-09-08T03:27:18.343242Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "{\n",
       "    \"conference_name\": \"Стратегическое планирование\",\n",
       "    \"conference_date\": \"2023-09-27\",\n",
       "    \"users_name\": [\n",
       "        \"Яна\", \n",
       "        \"Аня\", \n",
       "        \"Егор\"\n",
       "    ],\n",
       "    \"user_status\": [\n",
       "        \"участник\", \n",
       "        \"участник\", \n",
       "        \"участник\"\n",
       "    ],\n",
       "    \"question_title\": [\n",
       "        \"Обзор прошлого совещания\", \n",
       "        \"Задачи на будущее\", \n",
       "        \"Команда и организация\", \n",
       "        \"Знакомство с коллегами\", \n",
       "        \"Перспективы развития\", \n",
       "        \"Опыт взаимодействия\", \n",
       "        \"Сложности в работе\", \n",
       "        \"Развитие навыков\", \n",
       "        \"Важные задачи\", \n",
       "        \"План на завтра\"\n",
       "    ],\n",
       "    \"questions\": [\n",
       "        \"Какое впечатление осталось от предыдущего совещания и что можно улучшить в будущем\", \n",
       "        \"Что хотите сделать для организации и команды в ближайшее время\", \n",
       "        \"Расскажите о своих впечатлениях от сегодняшнего знакомства с коллегами\", \n",
       "        \"Какие перспективы развития видит команда\", \n",
       "        \"Какой опыт получили от взаимодействия с коллегами\", \n",
       "        \"Какие сложности возникли в процессе работы\", \n",
       "        \"Как развивать свои навыки и налаживать связи внутри команды\", \n",
       "        \"Какие важные задачи были выполнены сегодня\", \n",
       "        \"Какой план действий на завтра\", \n",
       "        \"Какие встречи запланированы на следующий день\"\n",
       "    ],\n",
       "    \"solutions\": [\n",
       "        \"Анализировать прошлые совещания и делать выводы для улучшения\", \n",
       "        \"Определить цели и задачи для организации и команды\", \n",
       "        \"Продолжать знакомиться и взаимодействовать с коллегами\", \n",
       "        \"Обсуждать перспективы развития и возможности роста\", \n",
       "        \"Обмениваться опытом и знаниями\", \n",
       "        \"Решать возникающие проблемы совместно\", \n",
       "        \"Налаживать коммуникацию и создавать пространство для самореализации\", \n",
       "        \"Выполнить срочные задачи и подготовить презентацию\", \n",
       "        \"Завершить работу над текущими проектами\", \n",
       "        \"Запланировать встречи и распределить обязанности\"\n",
       "    ],\n",
       "    \"responsible_person\": [\n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\", \n",
       "        \"Все участники\"\n",
       "    ],\n",
       "    \"time_for_solutions\": [\n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\", \n",
       "        \"неизвестно\"\n",
       "    ]\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<ml_kernel._vendor.IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_content(text):\n",
    "    display(Markdown(f'```\\n{text}\\n```'))\n",
    "    \n",
    "    \n",
    "display_content(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682eca9-f7f8-4da3-a8a5-e196fb702ae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-08T03:41:58.681792Z",
     "iopub.status.busy": "2024-09-08T03:41:58.681395Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.rand(20, 20)\n",
    "b = torch.rand(20, 200)\n",
    "\n",
    "while 1:\n",
    "    c = a @ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a8738-405f-49b7-94a2-19c612131217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
